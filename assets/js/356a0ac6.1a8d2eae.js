"use strict";(self.webpackChunktailcall_in=self.webpackChunktailcall_in||[]).push([[1117],{3905:(e,t,n)=>{n.d(t,{Zo:()=>h,kt:()=>u});var i=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},o=Object.keys(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=i.createContext({}),c=function(e){var t=i.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},h=function(e){var t=c(e.components);return i.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},d=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,l=e.parentName,h=s(e,["components","mdxType","originalType","parentName"]),d=c(n),u=a,f=d["".concat(l,".").concat(u)]||d[u]||p[u]||o;return n?i.createElement(f,r(r({ref:t},h),{},{components:n})):i.createElement(f,r({ref:t},h))}));function u(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,r=new Array(o);r[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,r[1]=s;for(var c=2;c<o;c++)r[c]=n[c];return i.createElement.apply(null,r)}return i.createElement.apply(null,n)}d.displayName="MDXCreateElement"},7384:(e,t,n)=>{n.r(t),n.d(t,{contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var i=n(7462),a=(n(7294),n(3905));const o={title:"About"},r=void 0,s={type:"mdx",permalink:"/about",source:"@site/src/pages/about.md",title:"About",description:"Tailcall's API Developer Platform intends to solve one of the most forsaken pieces of every microservice architecture \u2014 API Composition.",frontMatter:{title:"About"}},l=[{value:"Microservice",id:"microservice",level:2},{value:"API Composition",id:"api-composition",level:2},{value:"Backend For Frontend",id:"backend-for-frontend",level:2},{value:"Highly Specialized",id:"highly-specialized",level:3},{value:"Fragile",id:"fragile",level:3},{value:"Performance",id:"performance",level:3},{value:"Monolith",id:"monolith",level:3},{value:"Canary Support (Lack thereof)",id:"canary-support-lack-thereof",level:3},{value:"Coupled Release",id:"coupled-release",level:3},{value:"Legacy Gateway",id:"legacy-gateway",level:3}],c={toc:l};function h(e){let{components:t,...o}=e;return(0,a.kt)("wrapper",(0,i.Z)({},c,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Tailcall's ",(0,a.kt)("strong",{parentName:"p"},"API Developer Platform")," intends to solve one of the most forsaken pieces of every microservice architecture \u2014 API Composition.\nSome of the ideas used in tailcall's solution are developed over years of experience in working at scale.\nBefore we go deeper into API Composition, let's do a quick recap of what a microservice architecture looks like"),(0,a.kt)("h2",{id:"microservice"},"Microservice"),(0,a.kt)("p",null,"Microservices architecture is a design pattern in which a large application is built as a suite of modular services, each of which runs its process and communicates with other services through well-defined interfaces, typically using a lightweight messaging protocol. This approach has several benefits over a monolithic architecture, including improved scalability, resilience, and maintainability. In a microservices architecture, each service has a specific role and is independently deployable, so developers can work on different services in parallel and deploy them independently of each other. This can make the development process more agile and allow for faster deployment of new features."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"microservice",src:n(6875).Z,width:"3014",height:"2260"})),(0,a.kt)("p",null,'An API gateway is a server that acts as a single point of entry for certain types of requests. It can receive requests from the client, route them to the appropriate backend service, and then return the response from the backend service to the client. An API gateway can also perform tasks such as authentication, rate limiting, and caching. This makes it a useful component in a microservices architecture, where each service has its API and the API gateway acts as the "front door" for clients to access the services.'),(0,a.kt)("h2",{id:"api-composition"},"API Composition"),(0,a.kt)("p",null,"API composition refers to the process of combining multiple APIs to create a new API or a new functionality. This can be done by sending requests to multiple APIs and combining the results, or by creating a new API that acts as a fa\xe7ade for the underlying APIs."),(0,a.kt)("p",null,"For example, consider a scenario where a client application wants to display a user's profile information and recent posts on a social media platform. In this case, the client can send two separate requests to two different APIs: one to retrieve the user's profile information, and another to retrieve their recent posts. The client can then combine the results from these two APIs to create a single response that contains all the required information. This new response can be considered as the output of the composed API."),(0,a.kt)("p",null,"To build a rich user interface, API composition is necessary on the client side.\nOne of the main challenges with API composition on the client side is that it can lead to increased complexity in the client application. This is because the client needs to handle the process of sending requests to multiple APIs and combining the results, which can add to the overall size and complexity of the client code."),(0,a.kt)("p",null,"Another challenge with API composition on the client side is that it can result in reduced performance and increased latency. This is because the client needs to make multiple separate requests to different APIs, which can take more time and result in a slower response from the composed API."),(0,a.kt)("p",null,"In addition, API composition on the client side can also lead to increased security risks. This is because the client needs to handle sensitive information, such as API keys and authentication credentials, which can be vulnerable to attacks if not properly secured.\nThe client doesn't have access to powerful CPUs or a reliable network either. This makes the composition problem even more challenging to implement and manage. It is therefore often more efficient and effective to perform API composition on the server side instead."),(0,a.kt)("h2",{id:"backend-for-frontend"},"Backend For Frontend"),(0,a.kt)("p",null,"A BFF layer can help to solve the challenges of API composition by providing a separate backend service that is optimized for each specific frontend client. This can enable the BFF to perform API composition on behalf of the client, which can help to improve the performance and reliability of the composed API. The BFF layer typically sits as a separate component in the overall architecture, between the frontend client and the microservices. It can communicate with both the frontend client and the microservices using well-defined interfaces and protocols, such as REST or gRPC."),(0,a.kt)("p",null,"The BFF can take advantage of a powerful CPU and access to a fast network to improve the performance and reliability of the composed API. It can also provide added flexibility and control over the composition process. This can make it a useful tool for developers who want to create new APIs by combining the functionality of multiple underlying APIs."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Backend for Frontend",src:n(1801).Z,width:"3617",height:"2224"})),(0,a.kt)("h3",{id:"highly-specialized"},"Highly Specialized"),(0,a.kt)("p",null,"One of the challenges with using a BFF layer is that it is a highly specialized solution that requires a significant amount of hand-written code. Unlike an API gateway, there is no standard BFF solution that can be deployed out-of-the-box, and each BFF implementation must be custom-tailored to the specific requirements of the frontend client. This lack of standardization and reusability can make the BFF solution more complex and difficult to maintain."),(0,a.kt)("h3",{id:"fragile"},"Fragile"),(0,a.kt)("p",null,"Another challenge with using a BFF layer is that it can be fragile and susceptible to failure. The BFF solution is dependent on the developers to follow best practices and handle all error scenarios, and if these steps are not taken, the solution can be prone to bugs and performance issues. Additionally, the BFF solution must be thoroughly tested, including performance testing, unit testing, and integration testing, to ensure that it is reliable and performs well in production. This can require significant effort and expertise, and if these steps are not properly followed, the BFF solution can be fragile and prone to failure. Also, it's worth mentioning that a BFF layer is an entry point to all your backend, it going down basically means nothing is accessible for the user so this layer needs to be robust and resilient to exceptions."),(0,a.kt)("h3",{id:"performance"},"Performance"),(0,a.kt)("p",null,"Because BFF layers are typically custom-written for each use case, it can be difficult to predict the performance impact of a small code change. Issues such as unoptimized algorithms, inefficient caching, and unnecessary downstream requests can go unnoticed and only be discovered very late in the development cycle. Typically companies perform thorough benchmarking and load testing before anything goes live. This results in a very high time to market even for minor changes."),(0,a.kt)("h3",{id:"monolith"},"Monolith"),(0,a.kt)("p",null,"Eventually, this layer turns out to be a big monolith touching every service in your backend. The layer contains a lot of handwritten spaghetti code that's hard to maintain. Onboarding new engineers also become harder and upgrading libraries or architecture gets costlier. Any tiny change requires a full-fledged deployment on your infrastructure."),(0,a.kt)("h3",{id:"canary-support-lack-thereof"},"Canary Support (Lack thereof)"),(0,a.kt)("p",null,"Every change that happens in the backend requires the deployment of the BFF layer. In fact, any feature that is built on the client also requires changes on the BFF layer. Such frequent changes can not be exposed to 100% of users because the reliability and performance of this system are unknown. A common way to solve this problem is to use ",(0,a.kt)("a",{parentName:"p",href:"https://www.redhat.com/en/topics/devops/what-is-blue-green-deployment"},"Blue Green")," deployments. This requires additional infrastructure and complex routing mechanisms. A first-class support to do canary releases is very important and should be part of a modern BFF layer, however, most companies rely on DevOps for its support."),(0,a.kt)("h3",{id:"coupled-release"},"Coupled Release"),(0,a.kt)("p",null,"BFF layers can't be deployed independently since they act as a bridge between the clients and the services. Generally, the services need to go live first, and they need to make sure that the change is compatible with the current version of the BFF layer running in production. The interesting problem is in case there is a bug in the microservice and it needs to be reverted, even the BFF layer needs to be reverted. This kind of coupling makes it operationally very expensive to manage."),(0,a.kt)("h3",{id:"legacy-gateway"},"Legacy Gateway"),(0,a.kt)("p",null,"BFF layers often end up implementing some of the cross-cutting concerns of an API gateway such as rate limiting, authentication, throttling etc. This makes its purpose quite confusing in the sense that do we need an API gateway if we are using a BFF layer? Moreover, it's not very clear if we use an API gateway with a BFF layer, where should we place it? Should we place it between the clients and the BFF layer or the BFF layer and the service mesh? These are subjective decisions that each company ends up making as there is no standard way of doing this. However, it's worth mentioning that legacy gateways do introduce a gap that's being attempted to be filled by a BFF layer."),(0,a.kt)("hr",null),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"PS:")," If you were looking for the technical meaning of tailcall then the following might be a good starting point -"),(0,a.kt)("p",null,"From ",(0,a.kt)("em",{parentName:"p"},(0,a.kt)("a",{parentName:"em",href:"https://en.wikipedia.org/wiki/Tail_call"},"Wikipedia"))),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"In computer science, a tail call is a subroutine call performed as the final action of a procedure.")),(0,a.kt)("p",null,"The basic idea is that it's a function call that is made at a place where no stack allocations are required. This happens when the caller of the function is simply returning the result of the called function. This optimization doesn't have any performance impact however it gives us the flexibility to design and implement mutually recursive functions."))}h.isMDXComponent=!0},1801:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/bff-878ce671177c6fa3e99bf82f002c2b17.svg"},6875:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/microservices-470f369493a95674ec72436df9d40ce3.svg"}}]);